{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# модуль библиотеки OpenCV для работы с изображениями\n",
    "import cv2\n",
    "\n",
    "# всякие полезные библиотеки для работы с матрицами / отрисовки / etc.\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import os\n",
    "from os.path import basename # чтобы достать имя файла из пути\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самолёты я беру из следующих аэропортов:\n",
    "\n",
    "vko18-gr-small.jpg\n",
    "\n",
    "jto17-gr1-small.jpg\n",
    "\n",
    "dme18-gr1-small.jpg.\n",
    "\n",
    "Т.к. будет аугментация (поворот), то надо брать изображение, где самолёт далеко от краёв, чтобы оно влезло"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подгружаем данные, смотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PATH_TEST = \"/srv/samba/share/data/airbus/test/color/1/\"\n",
    "PATH_TEST = \"/srv/samba/share/data/airbus/test/validate/mini/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Будет лучше, если положительных и отрицательных примеров будет поровну\n",
    "pos_size = 487\n",
    "neg_size = 1639 \n",
    "PATH_POS = \"/srv/samba/share/data/airbus/train/16/\"\n",
    "# 11 = 57\n",
    "# 12 = 30 <---\n",
    "# 13 = 97\n",
    "# 14 = 101\n",
    "# 15 = 720\n",
    "# 16 = 384\n",
    "# 3+4c+add1 = 415\n",
    "# 17 = 487\n",
    "\n",
    "PATH_NEG = \"/srv/samba/share/data/airbus/fail/16+17+/\"\n",
    "# 11 = 40 <---\n",
    "# 12 = 960\n",
    "# 13 = 539\n",
    "# 14 = 4292\n",
    "# 15 = 462? 476\n",
    "# 3+4c+add1 = 626\n",
    "# 17 = 814\n",
    "# 16+17 = 1458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучающая выборка, самолёты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " По идее ОБРЕЗАНИЕ (image = cv2.resize(cv2.imread(name, cv2.IMREAD_GRAYSCALE), (64, 64))) не надо делать, потому что потом надо делать аугментацию. Лучше это сделать после аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_faces(path, number):\n",
    "    \"\"\"\n",
    "    Функция для загрузки изображений из папки по пути path.\n",
    "    \"\"\"\n",
    "    names = glob.glob(path + \"*.*\")\n",
    "    data = []\n",
    "    for name in tqdm.tqdm_notebook(names[:number]):\n",
    "        image = cv2.resize(cv2.imread(name, cv2.IMREAD_GRAYSCALE), (64, 64))\n",
    "#         image = cv2.imread(name, cv2.IMREAD_GRAYSCALE)\n",
    "        data.append(image)\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b89f1d2141455b9d1349e1451427d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read 487 images, \n",
      "data_pos shape is (384, 64, 64), \n",
      "labels_pos shape is (384, 1)\n"
     ]
    }
   ],
   "source": [
    "data_pos = read_faces(path=PATH_POS, number=pos_size) # получим np.array с N_FACES изображениями лиц размера (64, 64)\n",
    "labels_pos = np.ones(shape=(len(data_pos), 1)) # np.array c единичками \n",
    "print(\"Read %d images, \\ndata_pos shape is %s, \\nlabels_pos shape is %s\" % (pos_size, data_pos.shape, labels_pos.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def show_random_images(data, size = 5):\n",
    "    \"\"\"\n",
    "    Функция для отрисовки size x size случайных изображений из data.\n",
    "    \"\"\"\n",
    "    random_idxs = np.random.randint(0, len(data), size ** 2)\n",
    "    \n",
    "    plt.figure(figsize=(12 ,5))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            \n",
    "            num = i * size + j\n",
    "            plt.subplot(size, size, num + 1)\n",
    "            pic = cv2.resize(data[num], (64, 64))\n",
    "            pic = data[num]\n",
    "            plt.imshow(pic, cmap='gray')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print(data_pos[0])\n",
    "# print( cv2.resize(data_pos[0],(64,64)) )\n",
    "\n",
    "plt.subplot(1,2,1), plt.imshow(data_pos[0])\n",
    "# plt.subplot(1,2,2), plt.imshow(cv2.resize(data_pos[0][20:100,20:100] ,(64,64)))\n",
    "# plt.subplot(1,2,2), plt.imshow( data_pos[0][20:100,20:100] )\n",
    "plt.show\n",
    "# print( len(data_pos[0][20:84,20:84]) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "show_random_images(data_pos, size=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# сохраняем выборку на диск\n",
    "i = 0\n",
    "for item in data_pos:\n",
    "    cv2.imwrite('faces/'+str(i)+'.jpg',item)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучающая выборка, фоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_backgrounds(path, number):\n",
    "    names = glob.glob(path + \"*.*\")\n",
    "    data = []\n",
    "    for name in tqdm.tqdm_notebook(names[:number]):\n",
    "        image = cv2.resize(cv2.imread(name, cv2.IMREAD_GRAYSCALE), (64, 64))\n",
    "#         image = cv2.imread(name, cv2.IMREAD_GRAYSCALE)\n",
    "        data.append(image)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ff1ee91169452a856c35880cc209bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read 1639 images, \n",
      "data_neg shape is (1639, 64, 64), \n",
      "labels_neg shape is (1639, 1)\n"
     ]
    }
   ],
   "source": [
    "data_neg = read_backgrounds(path=PATH_NEG, number=neg_size)\n",
    "labels_neg = np.zeros((len(data_neg), 1)) # np.array с нулями\n",
    "print(\"Read %d images, \\ndata_neg shape is %s, \\nlabels_neg shape is %s\" % (neg_size, data_neg.shape, labels_neg.shape))\n",
    "\n",
    "# for one iamge we make (angle_to-angle_from)/angle_step + \"1 original\"  images\n",
    "# size of out must be  [(angle_to-angle_from)/angle_step + \"1 original\" ]* \"count of images\"\n",
    "# so [(360-45)/45 + 1] * 40 = 960"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "show_random_images(data_neg, size=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# сохраняем выборку на диск\n",
    "i = 0\n",
    "for item in data_neg:\n",
    "    cv2.imwrite('faces/'+str(i)+'.jpg',item)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### объединяем всё в обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (2023, 64, 64),\n",
      "Shape of y is (2023, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([data_pos, data_neg])\n",
    "y = np.concatenate([labels_pos, labels_neg])\n",
    "del data_pos, data_neg, labels_pos, labels_neg\n",
    "print(\"Shape of X is %s,\\nShape of y is %s\" % (X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Пишем функцию для извлечения HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_vector(grayscale_image):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая вектор HOG для одного grayscale-изображения размера (64 x 64). \n",
    "    Возвращаемый вектор имеет вид (1 x длина вектора HOG).\n",
    "    \"\"\"\n",
    "    \n",
    "    image_resized = cv2.resize(grayscale_image, (64, 64))\n",
    " \n",
    "    hog_descriptor = cv2.HOGDescriptor((64, 64), #winsize\n",
    "                                       (32, 32), #blocksize\n",
    "                                       (16, 16), #blockstride\n",
    "                                       (8, 8),   #cellsize\n",
    "                                       9)        #nbins\n",
    "\n",
    "    return hog_descriptor.compute(image_resized).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_matrix(array_images):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая матрицу, i-я строка которой является вектором HOG для i-го изображения \n",
    "    входного массива.\n",
    "    Возвращаемая матрица имеет вид (число изображений x длина вектора HOG)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ваш код здесь\n",
    "    \n",
    "#     matrix = np.array([get_hog_vector(image.reshape(128, 128)).flatten() for image in array_images]) \n",
    "    matrix = np.array([get_hog_vector(image.reshape(64, 64)).flatten() for image in array_images]) \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_hog = get_hog_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучаем SVM на признаках HOG нашего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Отмасштабируем наши признаки, чтобы среднее значение и дисперсия каждого из признаков были равны 0 и 1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_hog = scaler.fit_transform(X_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# модули для оптимизации моделей машинного обучения\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_hog, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(C=1e-2, kernel='linear', probability=True)\n",
    "# svm = SVC(C=1e-1, kernel='sigmoid', probability=True)\n",
    "svm.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Ваш код здесь (по желанию)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is  0.9638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0    0.97320   0.98129   0.97723       481\n",
      "        1.0    0.92623   0.89683   0.91129       126\n",
      "\n",
      "avg / total    0.96345   0.96376   0.96354       607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on test set is % .4f\" % accuracy_score(y_test, y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "info = svm.fit(X_hog, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Пишем функцию для реализации метода sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fileName(path):\n",
    "    words = re.split('_',basename(path))[:1]\n",
    "    return '_'.join(words)+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_face(image, box):\n",
    "    y1, x1, y2, x2 = box                      # получаем координаты очередного окна (bbox-а)\n",
    "    bbox = image[y1:y2, x1:x2]                # \"вырезаем\" из изображения это окно\n",
    "    hog = get_hog_vector(bbox)                # подаем на вход функции, вычисляющей HOG\n",
    "    hog_tr = scaler.transform(hog)            # нормируем вектор\n",
    "    return svm.predict_proba(hog_tr)[0][1], bbox # с помощью модели предсказываем для окна \"вероятность быть самолётом\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### скользящее окно с масштабированием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window_multiscale(image, winside=64, step=64, scales=(0.75, 1, 1.25)):\n",
    "    \"\"\"\n",
    "    Функция-генератор для сканирования изображения окном размера (winside x winside) с шагом step.\n",
    "    Последовательно сканируются изображения в масштабах из scales.\n",
    "    Возвращает 4-кортеж вида (y1, x1, y2, x2).\n",
    "    В чем отличие от sliding_window(...)?\n",
    "    \"\"\"\n",
    "    for scale in scales:\n",
    "        if min(image.shape) < winside / scale:\n",
    "            continue\n",
    "            \n",
    "        for i in range(0, int((image.shape[0] * scale - winside) / step + 1)):\n",
    "            for j in range(0, int((image.shape[1] * scale - winside) / step + 1)):\n",
    "                yield (int(i * step / scale), \n",
    "                       int(j * step / scale), \n",
    "                       int((i * step + winside) / scale), \n",
    "                       int((j * step + winside) / scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh=0.2):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    " \n",
    "    pick = []\n",
    " \n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    " \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    " \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    " \n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    " \n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    " \n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_on_families_multiscale(scaler, estimator, path, thres=0.95):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для загрузки и сканирования тестовых изображений и отрисовки найденных лиц на них.\n",
    "    Изучите работу функции.\n",
    "    \"\"\"\n",
    "    families_list = glob.glob(path + \"*.*\") # получаем список имен файлов с изображениями\n",
    "    print(families_list)\n",
    "\n",
    "    maxv = 255\n",
    "    for family in families_list:\n",
    "#     for family in tqdm.tqdm_notebook(families_list):\n",
    "        image = cv2.imread(family, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # применяем пороги 175, 200, 235 к изображениям\n",
    "        ret,thresh1 = cv2.threshold(image,175,maxv,cv2.THRESH_BINARY_INV)\n",
    "        ret,thresh2 = cv2.threshold(image,200,maxv,cv2.THRESH_BINARY_INV)\n",
    "        ret,thresh3 = cv2.threshold(image,235,maxv,cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        cv2.imwrite(os.path.splitext(basename(family))[0]+'_othr1.jpg', thresh1)\n",
    "        cv2.imwrite(os.path.splitext(basename(family))[0]+'_othr2.jpg', thresh2)\n",
    "#         cv2.imwrite(os.path.splitext(basename(family))[0]+'_othr3.jpg', thresh3)\n",
    "#         break\n",
    "    \n",
    "#         image = cv2.pyrDown(image)                    # теперь в image лежит изображение\n",
    "        i = 0\n",
    "        face_boxes = []\n",
    "        is_face1s = []\n",
    "        is_face2s = []\n",
    "\n",
    "        for box in tqdm.tqdm_notebook(sliding_window_multiscale(image, step=8, scales=(0.75, 1, 1.25))):\n",
    "#         for box in tqdm.tqdm_notebook(sliding_window_multiscale(image, step=8, scales=(1,1) )):\n",
    "#         for box in sliding_window_multiscale(image, step=8, scales=(0.75, 1, 1.25)):\n",
    "        \n",
    "            is_face1, bbox1 = is_face(thresh1, box)\n",
    "            is_face2, bbox2 = is_face(thresh2, box)\n",
    "#             is_face3, bbox3 = is_face(thresh3, box)\n",
    "            is_face3 = 0.0\n",
    "            \n",
    "            if (is_face1 > thres) | (is_face2 > thres) | (is_face3 > thres): \n",
    "                face_boxes.append(box)                # если вероятность выше порога, сохраняем координаты окна\n",
    "#                 cv2.imwrite('faces/' + str(i) + '_thr.jpg', image) #пишем окно в файл чтобы потом его hard-negative mining\n",
    "#                 cv2.imwrite('faces/' + str(i) + '_1.jpg', bbox1) #пишем окно в файл чтобы потом его hard-negative mining\n",
    "#                 cv2.imwrite('faces/' + str(i) + '_2.jpg', bbox2) #пишем окно в файл чтобы потом его hard-negative mining\n",
    "#                 cv2.imwrite('faces/' + str(i) + '_3.jpg', bbox3) #пишем окно в файл чтобы потом его hard-negative mining\n",
    "#                 i = i+1\n",
    "    \n",
    "                is_face1s.append(is_face1)\n",
    "                is_face2s.append(is_face2)\n",
    "\n",
    "        face_boxes_filtered = non_max_suppression_fast(np.array(face_boxes), overlapThresh=0.2)\n",
    "\n",
    "        image_draw = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) # чтобы изображение было цветным\n",
    "        is_face1s = iter(is_face1s)\n",
    "        is_face2s = iter(is_face2s)\n",
    "\n",
    "#         for face_box in tqdm.tqdm_notebook(face_boxes_filtered):\n",
    "        for face_box in face_boxes_filtered:\n",
    "            cv2.rectangle(image_draw, (face_box[1], face_box[0]), \n",
    "                                      (face_box[3], face_box[2]), \n",
    "                                      (0, 0, 255), 1)\n",
    "            cv2.putText(image_draw, '{:.2f}'.format(next(is_face1s))+','+ '{:.2f}'.format(next(is_face2s)) ,(face_box[1], face_box[0]),cv2.FONT_HERSHEY_SIMPLEX,0.4,(15,255,15))\n",
    "            #пишем окно в файл чтобы потом его hard-negative mining\n",
    "#             cv2.imwrite('faces/' + str(i) + '_1.jpg', image[face_box[1]:face_box[0],face_box[3]:face_box[2]]) \n",
    "#             cv2.imwrite('faces/' + str(i) + '_1.jpg', thresh1[face_box[0]:face_box[2],face_box[1]:face_box[3]]) \n",
    "#             cv2.imwrite('faces/' + str(i) + '_2.jpg', thresh1[face_box[0]:face_box[2],face_box[1]:face_box[3]]) \n",
    "            i = i+1\n",
    "\n",
    "        image_draw = cv2.putText(image_draw,'Image=' + family.split('/')[-1],(10,35),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "#         image_draw = cv2.putText(image_draw,'DIR_POS='+PATH_POS.split('/')[-2],(10,70),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "#         image_draw = cv2.putText(image_draw,'DIR_NEG='+PATH_NEG.split('/')[-2],(10,105),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "#         image_draw = cv2.putText(image_draw,'pos_size='+str(pos_size),(10,140),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "#         image_draw = cv2.putText(image_draw,'neg_size='+str(neg_size),(10,175),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "#         image_draw = cv2.putText(image_draw,'svminfo='+repr(info),(10,210),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "#         image_draw = cv2.putText(image_draw,'thr='+str(thres),(10,245),cv2.FONT_HERSHEY_SIMPLEX,1,(255,15,15))\n",
    "        cv2.imwrite(os.path.splitext(basename(family))[0]+'_out.jpg', image_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/srv/samba/share/data/airbus/test/validate/mini/lga18-1-mini1.jpg', '/srv/samba/share/data/airbus/test/validate/mini/led18-mini.jpg', '/srv/samba/share/data/airbus/test/validate/mini/sip18-mini.jpg', '/srv/samba/share/data/airbus/test/validate/mini/lga18-1-mini2.jpg']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e536e6a4d1c4038b1775c3cad14402a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3322f485dbad43c19e9946a66905a3b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c648137b489248699e7f8c1ced84c86a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.rcParams['figure.figsize'] = (30, 30)\n",
    "%time check_on_families_multiscale(scaler, svm, path=PATH_TEST, thres=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идеи на потом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Реализовать отдельный классификатор по уровням фильтрации порога. А может и не нужно, потому что \n",
    "2. Реализовать двойной фильтр как в Гимпе. Уж очень он хороший результат дал для первой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
